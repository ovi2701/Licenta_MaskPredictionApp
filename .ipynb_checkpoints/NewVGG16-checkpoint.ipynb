{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f87e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vgg16_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5132\\1129038838.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"softmax\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m \u001b[0mvgg16_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;31m# compile our model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vgg16_model' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "\n",
    "#path to folders for training data\n",
    "mask_path = Path(\"dataset\") / \"with_mask\"\n",
    "no_mask_path = Path(\"dataset\") / \"without_mask\"\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "print(\"Load data...\")\n",
    "\n",
    "for img in mask_path.glob(\"*.jpg\"):\n",
    "    #Load the image from disk\n",
    "    img = image.load_img(img)\n",
    "    \n",
    "    img = img.resize([224,224])\n",
    "    \n",
    "    #Convert the image to an array\n",
    "    image_array = image.img_to_array(img)\n",
    "    \n",
    "    #Add the image to the list of images\n",
    "    images.append(image_array)\n",
    "    \n",
    "    #For each \"mask image\", the expected value should be 1\n",
    "    labels.append(1)\n",
    "\n",
    "for img in no_mask_path.glob(\"*.jpg\"):\n",
    "    #Load the image from disk\n",
    "    img = image.load_img(img)\n",
    "    \n",
    "    img = img.resize([224,224])\n",
    "    \n",
    "    #Convert the image to an array\n",
    "    image_array = image.img_to_array(img)\n",
    "    \n",
    "    #Add the image to the list of images\n",
    "    images.append(image_array)\n",
    "    \n",
    "    #For each \"not mask image\", the expected value should be 0\n",
    "    labels.append(0)\n",
    " \n",
    "\n",
    "    # Convert the array with train images we loaded into a numpy array\n",
    "X_train = np.array(images)\n",
    "\n",
    "# Convert the train lables array into a numpy array\n",
    "Y_train = np.array(labels)\n",
    "\n",
    "# transform labels into arrays with two elements\n",
    "Y_train = to_categorical(Y_train)\n",
    "\n",
    "# Convert data from integer to floating point\n",
    "X_train = X_train.astype(\"float32\")\n",
    "\n",
    "# Normalizing data between 0 and 1\n",
    "X_train = X_train/255\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(X_train, Y_train,\n",
    "\ttest_size=0.20, stratify=labels, random_state=42)\n",
    "\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# Load VGG16 network and make layers non trainable\n",
    "vgg = VGG16(weights='imagenet', include_top=False, input_shape = (224,224,3))\n",
    "\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(vgg)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "history = model.fit_generator(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tepochs=EPOCHS)\n",
    "    \n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"VGG16Mask.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0b4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
