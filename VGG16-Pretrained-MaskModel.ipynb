{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d953362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, AveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.applications import vgg16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c87c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to folders for training data\n",
    "mask_path= Path(\"Face Mask Dataset\") / \"Train\" / \"WithMask\"\n",
    "no_mask_path= Path(\"Face Mask Dataset\") / \"Train\" / \"WithoutMask\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da6e6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 5\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d33007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6d95921",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in no_mask_path.glob(\"*.png\"):\n",
    "    #Load the image from disk\n",
    "    img = image.load_img(img)\n",
    "    \n",
    "    img = img.resize([224,224])\n",
    "    \n",
    "    #Convert the image to an array\n",
    "    image_array = image.img_to_array(img)\n",
    "    \n",
    "    #Add the image to the list of images\n",
    "    images.append(image_array)\n",
    "    \n",
    "    #For each \"not mask image\", the expected value should be 0\n",
    "    labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b75193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in mask_path.glob(\"*.png\"):\n",
    "    #Load the image from disk\n",
    "    img = image.load_img(img)\n",
    "    \n",
    "    img = img.resize([224,224])\n",
    "    \n",
    "    #Convert the image to an array\n",
    "    image_array = image.img_to_array(img)\n",
    "    \n",
    "    #Add the image to the list of images\n",
    "    images.append(image_array)\n",
    "    \n",
    "    #For each \"mask image\", the expected value should be 1\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33742218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the array with images we loaded into a numpy array\n",
    "images = np.array(images, dtype=\"float32\")\n",
    "\n",
    "# Convert the lables array into a numpy array\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c3457c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image data for train between 0 and 1\n",
    "images = images/255\n",
    "\n",
    "# Convert labels to categorical\n",
    "labels = to_categorical(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e207dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(images, labels,test_size=0.2, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ae1e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e621b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training head...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "250/250 [==============================] - 1611s 6s/step - loss: 0.6203 - accuracy: 0.6939 - val_loss: 0.4333 - val_accuracy: 0.8885\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 1589s 6s/step - loss: 0.4292 - accuracy: 0.8679 - val_loss: 0.2909 - val_accuracy: 0.9200\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 1566s 6s/step - loss: 0.3216 - accuracy: 0.9078 - val_loss: 0.2172 - val_accuracy: 0.9335\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 1566s 6s/step - loss: 0.2636 - accuracy: 0.9184 - val_loss: 0.1686 - val_accuracy: 0.9485\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 1575s 6s/step - loss: 0.2285 - accuracy: 0.9245 - val_loss: 0.1541 - val_accuracy: 0.9435\n",
      "[INFO] saving mask detector model...\n"
     ]
    }
   ],
   "source": [
    "# load the vgg16 network, ensuring the head FC layer sets are\n",
    "# left off\n",
    "baseModel = VGG16(weights=\"imagenet\",input_shape=(224,224,3), include_top=False)\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY),\n",
    "    epochs=EPOCHS)\n",
    "\n",
    "# # make predictions on the testing set\n",
    "# print(\"[INFO] evaluating network...\")\n",
    "# predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# # for each image in the testing set we need to find the index of the\n",
    "# # label with corresponding largest predicted probability\n",
    "# predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# # show a nicely formatted classification report\n",
    "# print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "#     target_names=lb.classes_))\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"VGGMaskDetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc24816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
